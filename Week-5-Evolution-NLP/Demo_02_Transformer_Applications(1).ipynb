{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b2eaba0-e4d5-430f-8cdc-5db4e71eed2e",
   "metadata": {
    "id": "0b2eaba0-e4d5-430f-8cdc-5db4e71eed2e"
   },
   "source": [
    "# __Demo: Transformer Applications__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267cf3c8-157a-4acf-bf13-7cf78d407bb5",
   "metadata": {
    "id": "267cf3c8-157a-4acf-bf13-7cf78d407bb5"
   },
   "source": [
    "The text below includes two sections, text1 and text2. `text1` presents a customer's negative review, while `text2` provides a positive review. This demo aims to demonstrate the Transformer models' ability to manage two distinct tasks effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f23079c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = '''Deeply dissatisfied with my recent Samsung Galaxy purchase. The phone freezes unexpectedly, \n",
    "and the battery drains far too quickly, barely lasting half a day. For the price I paid, I anticipated \n",
    "reliable performance, but instead, it feels sluggish and frustrating to use. Reaching out to customer \n",
    "support hasn’t helped—responses have been generic and unhelpful, leaving my issues unresolved. I regret \n",
    "choosing Samsung this time, as the experience has been far below the standard I expected from a brand \n",
    "with such a strong reputation.  \n",
    "'''\n",
    "\n",
    "text2 = '''I recently bought a Samsung Galaxy phone, and I couldn’t be happier with my decision! The \n",
    "device operates seamlessly, with apps opening instantly and multitasking handled with ease. The battery \n",
    "comfortably lasts the entire day, even with heavy usage, which makes it extremely dependable. Though the \n",
    "price is on the higher side, the excellent build quality, smooth performance, and responsive customer \n",
    "support make it completely worthwhile. I’m very satisfied with my purchase, and I’d highly recommend \n",
    "Samsung to anyone looking for a powerful and reliable smartphone.  \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3503b3-cc2b-4889-86d6-009f3f6ee49f",
   "metadata": {
    "id": "bf3503b3-cc2b-4889-86d6-009f3f6ee49f"
   },
   "source": [
    "# __Task 1: Text Classification__\n",
    "- Analyze customer reviews of purchase to classify the sentiment as positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ad9066b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0644d0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Lenovo\\anaconda3\\envs\\agentvenv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1 Sentiment: [{'label': 'NEGATIVE', 'score': 0.999439537525177}]\n",
      "Text 2 Sentiment: [{'label': 'POSITIVE', 'score': 0.9997257590293884}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"text-classification\") \n",
    "result1 = classifier(text1)\n",
    "result2 = classifier(text2)\n",
    "print(\"Text 1 Sentiment:\", result1)\n",
    "print(\"Text 2 Sentiment:\", result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc0a3781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# why classifier = pipeline(\"text-classification\") is for senement analysis?\n",
    "# The line classifier = pipeline(\"text-classification\") initializes a text classification pipeline using the Hugging Face Transformers library.\n",
    "# Text classification is a common natural language processing (NLP) task that involves categorizing text into predefined classes or labels.\n",
    "# Sentiment analysis is a specific type of text classification where the goal is to determine the sentiment expressed in a piece of text, typically categorizing it as positive, negative, or neutral.\n",
    "# By using pipeline(\"text-classification\"), the code sets up a model that can analyze the sentiment of the provided text inputs (text1 and text2) and classify them accordingly.        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da5f218f-96ba-4ca4-8f39-fa237ec0b050",
   "metadata": {
    "id": "da5f218f-96ba-4ca4-8f39-fa237ec0b050",
    "outputId": "bb460f09-01d9-4ee4-9931-e75ac4e1e411"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.99944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label    score\n",
       "0  NEGATIVE  0.99944"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "#text classification\n",
    "classifier = pipeline(\"text-classification\")\n",
    "import pandas as pd\n",
    "\n",
    "# Analyze for text1\n",
    "outputs1 = classifier(text1)\n",
    "pd.DataFrame(outputs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fef201ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers -U"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15835ef1-8663-4e43-8bcd-69498cd2f3b0",
   "metadata": {
    "id": "15835ef1-8663-4e43-8bcd-69498cd2f3b0"
   },
   "source": [
    "__Note:__ The output displays a label with its corresponding probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41c3d939-b400-4023-8657-49b6dd974662",
   "metadata": {
    "id": "41c3d939-b400-4023-8657-49b6dd974662",
    "outputId": "deec9711-7d12-4efc-db25-05de5a76a30d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.999726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label     score\n",
       "0  POSITIVE  0.999726"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ananlyze for text2:\n",
    "outputs2 = classifier(text2)\n",
    "pd.DataFrame(outputs2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7197ef88-c42e-4f51-9795-6d71612cdf6e",
   "metadata": {
    "id": "7197ef88-c42e-4f51-9795-6d71612cdf6e"
   },
   "source": [
    "# __Task 2: Text Generation__\n",
    "\n",
    "- Generate a customer service response to one of the reviews. This is achieved by using a text generation pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f633d96-01d8-4ef1-9b2d-b25726da9615",
   "metadata": {
    "id": "6f633d96-01d8-4ef1-9b2d-b25726da9615",
    "outputId": "48c800b5-b2c2-40df-8cf9-a39f29b9b77d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to openai-community/gpt2 and revision 607a30d (https://huggingface.co/openai-community/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cpu\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deeply dissatisfied with my recent Samsung Galaxy purchase. The phone freezes unexpectedly, \n",
      "and the battery drains far too quickly, barely lasting half a day. For the price I paid, I anticipated \n",
      "reliable performance, but instead, it feels sluggish and frustrating to use. Reaching out to customer \n",
      "support hasn’t helped—responses have been generic and unhelpful, leaving my issues unresolved. I regret \n",
      "choosing Samsung this time, as the experience has been far below the standard I expected from a brand \n",
      "with such a strong reputation.  \n",
      "\n",
      "\n",
      "Customer service response:\n",
      "Dear Customer, Thanks for writing in! I am sorry to hear your experience with us. \n",
      "\n",
      "This phone is\n"
     ]
    }
   ],
   "source": [
    "from transformers import set_seed\n",
    "set_seed(42) # Set the seed to get reproducible results\n",
    "\n",
    "generator = pipeline(\"text-generation\")\n",
    "response = \"Dear Customer, Thanks for writing in! I am sorry to hear your experience with us.\"\n",
    "prompt = text1 + \"\\n\\nCustomer service response:\\n\" + response\n",
    "outputs = generator(prompt, max_length=150)\n",
    "print(outputs[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de2a9f0-9756-4335-a84f-d0bf7eaf368b",
   "metadata": {
    "id": "5de2a9f0-9756-4335-a84f-d0bf7eaf368b"
   },
   "source": [
    "__Note:__ This demonstrates how Transformers can create context-aware responses, which can be a valuable tool in automated customer service or similar applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8fde87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install hf_xet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62099f30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "agentvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
